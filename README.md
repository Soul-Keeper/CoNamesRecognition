# Company Names Recognition

Данный проект реализует поиск похожих имен компаний в базе данных

## Исследование данных
В процессе разработки проекта нами было проведено исследование предоставленных данных. Они представлены в Data check.ipynb

В результате исследований мы поняли, что набор данных содержит маленькое количество пар дубликатов, из-за чего является очень не сбалансированным. Данные содержат большое кол-во сокращений/абривиатур/адресов - все это является лишней информацией, шумом. Также присутствуют строки на русском/арабском/китайском 

## Технологии
Для проведения сравнения имен между собой нами был выбран нейростевой подход с использованием трансформеров.
Для работы с трансформерами использовали библиотеку [SentenceTransformers](https://www.sbert.net/index.html)

## Обучение
Для обучения мы выбрали три самых быстрых модели из зоопарка предобученных, представленных на сайте библиотеки [Pretrained Models](https://www.sbert.net/docs/pretrained_models.html)

Данные для обучения мы выбрали так: взяли все пары дубликаты и дополнили набор до 7500 парами не дубликатами. Пары не дубликаты были выбраны случайным образом. Затем мы разделил набор на обучающую и тестовую подвыборку, 90% и 10% соответственно. Результаты представлены в таблице:
|     Модель                       |     Кол-во эпох    |     Accuracy    |     true positive    |     false positive    |     true negative    |     false negative    |
|----------------------------------|--------------------|-----------------|----------------------|-----------------------|----------------------|-----------------------|
|     all-MiniLM-L6-v2             |     0              |     67,5%       |     72               |     3                 |     547              |     294               |
|                                  |     1              |     94,8%       |     321              |     2                 |     548              |     45                |
|                                  |     10             |     98,4%       |     352              |     0                 |     550              |     14                |
|                                  |     50             |     99,0%       |     357              |     0                 |     550              |     9                 |
|     paraphrase-MiniLM-L3-v2      |     0              |     66,4%       |     60               |     1                 |     549              |     306               |
|                                  |     1              |     89,7%       |     274              |     2                 |     548              |     92                |
|                                  |     10             |     97,7%       |     345              |     0                 |     550              |     21                |
|                                  |     50             |     98,5%       |     353              |     0                 |     550              |     13                |
|     multi-qa-MiniLM-L6-cos-v1    |     0              |     67,7%       |     73               |     3                 |     547              |     293               |
|                                  |     1              |     95,8%       |     330              |     2                 |     548              |     36                |
|                                  |     10             |     98,1%       |     350              |     1                 |     549              |     16                |
|                                  |     50             |     98,9%       |     357              |     1                 |     549              |     9                 |

Время обучения каждой из модели в течении 50 эпох заняло 15 мин, 9 мин и 16 мин соответственно. Результаты сравнимы с представленными на сайте.


## Тестирование

В последствии была выбрана all-MiniLM-L6-v2. Её точность после 50 эпох обучения составила 99,0%. 
Для тестов были взяты все уникальные названия из предоставленного набора данных, их количество составило ~17000 наименований. Нашему алгоритму для поиска всех подобных названий понадобилось ~2 секунды, средняя скорость обработки ~7200 элементов в минуту (видеокарта при этом не использовалась)

Технические характеристики вычислительной машины на которой производились тесты: 
1. Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz
2. NVIDIA GeForce GTX 1050 Ti (Использовалась только для обучения и вычисления дескрипторов)
3. 16 GB DDR3


## Запуск

Для запуска необходимо установить библиотеки. Это можно сделать выполнив команду

```bash
pip install -r requirements.txt
```
## License
[MIT](https://choosealicense.com/licenses/mit/)
